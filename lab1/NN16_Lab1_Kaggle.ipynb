{"cells":[{"cell_type":"markdown","metadata":{"id":"Y4FkwFbb2rKC"},"source":["# Ομάδα 16\n","## Άγγελος Μητροκώτσας 03118197\n","## Ορέστης Ζάρας 03118207\n","## Γιώργος Τσιακατάρας 03118130"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29874,"status":"ok","timestamp":1670348796819,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"Xc5-3itRr9gq","outputId":"f3c3633b-8802-44c1-fbd5-cb95af6c68dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17708,"status":"ok","timestamp":1670348814522,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"lfw7T9f-Qm2J","outputId":"a3c93bea-9ad9-4a21-e8b7-19c21e1b5f2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-3.0.4-py3-none-any.whl (348 kB)\n","\u001b[K     |████████████████████████████████| 348 kB 18.7 MB/s \n","\u001b[?25hCollecting cliff\n","  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 8.3 MB/s \n","\u001b[?25hCollecting cmaes\u003e=0.8.2\n","  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n","Requirement already satisfied: scipy\u003c1.9.0,\u003e=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n","Requirement already satisfied: sqlalchemy\u003e=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.44)\n","Requirement already satisfied: importlib-metadata\u003c5.0.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (4.13.0)\n","Collecting alembic\u003e=1.5.0\n","  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n","Collecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (5.10.0)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata\u003c5.0.0-\u003eoptuna) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=20.0-\u003eoptuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy\u003e=1.3.0-\u003eoptuna) (2.0.1)\n","Collecting stevedore\u003e=2.0.1\n","  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n","\u001b[?25hCollecting cmd2\u003e=1.0.0\n","  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 22.8 MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable\u003e=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff-\u003eoptuna) (3.5.0)\n","Collecting autopage\u003e=0.4.0\n","  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n","Collecting pyperclip\u003e=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: wcwidth\u003e=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2\u003e=1.0.0-\u003ecliff-\u003eoptuna) (0.2.5)\n","Requirement already satisfied: attrs\u003e=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2\u003e=1.0.0-\u003ecliff-\u003eoptuna) (22.1.0)\n","Collecting pbr!=2.1.0,\u003e=2.0.0\n","  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 57.2 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe\u003e=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako-\u003ealembic\u003e=1.5.0-\u003eoptuna) (2.0.1)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=a22367803f457c6be04ca9c69480263ddf816c410ec1094737609407a7f61028\n","  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n","Successfully built pyperclip\n","Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.4 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.1\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2333,"status":"ok","timestamp":1670348816849,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"v-qI419wfsne"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.dummy import DummyClassifier\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import classification_report\n","\n","from sklearn.svm import SVC # \"Support vector classifier\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1375,"status":"ok","timestamp":1670348818215,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"LkuaHN28f0RH","outputId":"283d4816-21e3-46ff-d95b-4d0be2d63e68"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-638a9c63-7c3d-47ed-8a2e-13a58938f118\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ebuyin\u003c/th\u003e\n","      \u003cth\u003etourn_id\u003c/th\u003e\n","      \u003cth\u003etable\u003c/th\u003e\n","      \u003cth\u003ehand_id\u003c/th\u003e\n","      \u003cth\u003edate\u003c/th\u003e\n","      \u003cth\u003etime\u003c/th\u003e\n","      \u003cth\u003etable_size\u003c/th\u003e\n","      \u003cth\u003elevel\u003c/th\u003e\n","      \u003cth\u003eplaying\u003c/th\u003e\n","      \u003cth\u003eseat\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003epot_turn\u003c/th\u003e\n","      \u003cth\u003epot_river\u003c/th\u003e\n","      \u003cth\u003eante\u003c/th\u003e\n","      \u003cth\u003eblinds\u003c/th\u003e\n","      \u003cth\u003ebet_pre\u003c/th\u003e\n","      \u003cth\u003ebet_flop\u003c/th\u003e\n","      \u003cth\u003ebet_turn\u003c/th\u003e\n","      \u003cth\u003ebet_river\u003c/th\u003e\n","      \u003cth\u003eresult\u003c/th\u003e\n","      \u003cth\u003ebalance\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e2929450288\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e215051507105\u003c/td\u003e\n","      \u003ctd\u003e2020-06-07\u003c/td\u003e\n","      \u003ctd\u003e18:15:09\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003egave up\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e2929450288\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e215051507105\u003c/td\u003e\n","      \u003ctd\u003e2020-06-07\u003c/td\u003e\n","      \u003ctd\u003e18:15:09\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003egave up\u003c/td\u003e\n","      \u003ctd\u003e-10\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e2929450288\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e215051507105\u003c/td\u003e\n","      \u003ctd\u003e2020-06-07\u003c/td\u003e\n","      \u003ctd\u003e18:15:09\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e30\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003etook chips\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e2929450288\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e215051520234\u003c/td\u003e\n","      \u003ctd\u003e2020-06-07\u003c/td\u003e\n","      \u003ctd\u003e18:15:23\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e180\u003c/td\u003e\n","      \u003ctd\u003e180\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003etook chips\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e2929450288\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e215051520234\u003c/td\u003e\n","      \u003ctd\u003e2020-06-07\u003c/td\u003e\n","      \u003ctd\u003e18:15:23\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e180\u003c/td\u003e\n","      \u003ctd\u003e180\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003egave up\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e102610\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e3162349514\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e225348760558\u003c/td\u003e\n","      \u003ctd\u003e2021-03-30\u003c/td\u003e\n","      \u003ctd\u003e19:00:02\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e560\u003c/td\u003e\n","      \u003ctd\u003e560\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e500\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003etook chips\u003c/td\u003e\n","      \u003ctd\u003e60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e102611\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e3162349514\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e225348760558\u003c/td\u003e\n","      \u003ctd\u003e2021-03-30\u003c/td\u003e\n","      \u003ctd\u003e19:00:02\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e560\u003c/td\u003e\n","      \u003ctd\u003e560\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003egave up\u003c/td\u003e\n","      \u003ctd\u003e-20\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e102612\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e3162349514\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e225348768503\u003c/td\u003e\n","      \u003ctd\u003e2021-03-30\u003c/td\u003e\n","      \u003ctd\u003e19:00:25\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e390\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003elost\u003c/td\u003e\n","      \u003ctd\u003e-460\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e102613\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e3162349514\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e225348768503\u003c/td\u003e\n","      \u003ctd\u003e2021-03-30\u003c/td\u003e\n","      \u003ctd\u003e19:00:25\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e20\u003c/td\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e490\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ewon\u003c/td\u003e\n","      \u003ctd\u003e470\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e102614\u003c/th\u003e\n","      \u003ctd\u003e$0.92+$0.08\u003c/td\u003e\n","      \u003ctd\u003e3162349514\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e225348768503\u003c/td\u003e\n","      \u003ctd\u003e2021-03-30\u003c/td\u003e\n","      \u003ctd\u003e19:00:25\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e1030\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e10\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003egave up\u003c/td\u003e\n","      \u003ctd\u003e-10\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e102615 rows × 35 columns\u003c/p\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-638a9c63-7c3d-47ed-8a2e-13a58938f118')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-638a9c63-7c3d-47ed-8a2e-13a58938f118 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-638a9c63-7c3d-47ed-8a2e-13a58938f118');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["              buyin    tourn_id  table       hand_id        date      time  \\\n","0       $0.92+$0.08  2929450288      1  215051507105  2020-06-07  18:15:09   \n","1       $0.92+$0.08  2929450288      1  215051507105  2020-06-07  18:15:09   \n","2       $0.92+$0.08  2929450288      1  215051507105  2020-06-07  18:15:09   \n","3       $0.92+$0.08  2929450288      1  215051520234  2020-06-07  18:15:23   \n","4       $0.92+$0.08  2929450288      1  215051520234  2020-06-07  18:15:23   \n","...             ...         ...    ...           ...         ...       ...   \n","102610  $0.92+$0.08  3162349514      1  225348760558  2021-03-30  19:00:02   \n","102611  $0.92+$0.08  3162349514      1  225348760558  2021-03-30  19:00:02   \n","102612  $0.92+$0.08  3162349514      1  225348768503  2021-03-30  19:00:25   \n","102613  $0.92+$0.08  3162349514      1  225348768503  2021-03-30  19:00:25   \n","102614  $0.92+$0.08  3162349514      1  225348768503  2021-03-30  19:00:25   \n","\n","        table_size  level  playing  seat  ... pot_turn  pot_river ante blinds  \\\n","0                3      1        3     1  ...       30         30    0      0   \n","1                3      1        3     2  ...       30         30    0     10   \n","2                3      1        3     3  ...       30         30    0     20   \n","3                3      1        3     1  ...      180        180    0     20   \n","4                3      1        3     2  ...      180        180    0      0   \n","...            ...    ...      ...   ...  ...      ...        ...  ...    ...   \n","102610           3      1        3     2  ...      560        560    0     10   \n","102611           3      1        3     3  ...      560        560    0     20   \n","102612           3      1        3     1  ...     1030       1030    0     20   \n","102613           3      1        3     2  ...     1030       1030    0      0   \n","102614           3      1        3     3  ...     1030       1030    0     10   \n","\n","       bet_pre bet_flop bet_turn  bet_river      result balance  \n","0            0        0        0          0     gave up       0  \n","1           10        0        0          0     gave up     -10  \n","2           20        0        0          0  took chips      10  \n","3           60       60        0          0  took chips      60  \n","4            0        0        0          0     gave up       0  \n","...        ...      ...      ...        ...         ...     ...  \n","102610     500        0        0          0  took chips      60  \n","102611      20        0        0          0     gave up     -20  \n","102612      20       50      390          0        lost    -460  \n","102613      20       50      490          0         won     470  \n","102614      10        0        0          0     gave up     -10  \n","\n","[102615 rows x 35 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/one_dollar_spin_and_go.csv')\n","dataset = pd.read_csv('/content/drive/MyDrive/Νευρωνικά/one_dollar_spin_and_go.csv')\n","dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1670348818215,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"EyHRZ0kWDbfu","outputId":"a690d526-fab8-42c8-97b9-810b6e7897ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 102615 entries, 0 to 102614\n","Data columns (total 35 columns):\n"," #   Column        Non-Null Count   Dtype \n","---  ------        --------------   ----- \n"," 0   buyin         102615 non-null  object\n"," 1   tourn_id      102615 non-null  int64 \n"," 2   table         102615 non-null  int64 \n"," 3   hand_id       102615 non-null  int64 \n"," 4   date          102615 non-null  object\n"," 5   time          102615 non-null  object\n"," 6   table_size    102615 non-null  int64 \n"," 7   level         102615 non-null  int64 \n"," 8   playing       102615 non-null  int64 \n"," 9   seat          102615 non-null  int64 \n"," 10  name          102615 non-null  object\n"," 11  stack         102615 non-null  int64 \n"," 12  position      102615 non-null  object\n"," 13  action_pre    102615 non-null  object\n"," 14  action_flop   102615 non-null  object\n"," 15  action_turn   102615 non-null  object\n"," 16  action_river  102615 non-null  object\n"," 17  all_in        102615 non-null  bool  \n"," 18  cards         102615 non-null  object\n"," 19  board_flop    102615 non-null  object\n"," 20  board_turn    102615 non-null  object\n"," 21  board_river   102615 non-null  object\n"," 22  combination   18440 non-null   object\n"," 23  pot_pre       102615 non-null  int64 \n"," 24  pot_flop      102615 non-null  int64 \n"," 25  pot_turn      102615 non-null  int64 \n"," 26  pot_river     102615 non-null  int64 \n"," 27  ante          102615 non-null  int64 \n"," 28  blinds        102615 non-null  int64 \n"," 29  bet_pre       102615 non-null  int64 \n"," 30  bet_flop      102615 non-null  int64 \n"," 31  bet_turn      102615 non-null  int64 \n"," 32  bet_river     102615 non-null  int64 \n"," 33  result        102615 non-null  object\n"," 34  balance       102615 non-null  int64 \n","dtypes: bool(1), int64(19), object(15)\n","memory usage: 26.7+ MB\n"]}],"source":["dataset.shape\n","dataset.info()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1670348818215,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"PwtiU6K8GmiF","outputId":"eafc70a0-293a-4163-c8d7-8b2b7b1b78b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["#NaN in our dataset = 84175\n"]}],"source":["print(\"#NaN in our dataset =\", np.sum(np.sum(dataset.isna())))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670348818216,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"Cb7rF2djA-Vf","outputId":"23dd6b6b-4676-4e6e-8529-53106acc0be5"},"outputs":[{"name":"stdout","output_type":"stream","text":["The #No of attributes belonging to each class: \n"," [['gave up' 50728]\n"," ['lost' 10028]\n"," ['took chips' 31087]\n"," ['won' 10772]] \n","\n","The % percentage of attributes of each class: \n"," [['gave up', 49.435267748379864], ['lost', 9.772450421478341], ['took chips', 30.294791209862105], ['won', 10.497490620279686]]\n"]}],"source":["results = dataset.iloc[:,-2].values\n","freq = np.array(np.unique(results, return_counts=True)).T\n","percentage = []\n","for i in range(0,4):\n","  percentage.append([freq[i][0], freq[i][1] * 100/102615])\n","print(\"The #No of attributes belonging to each class: \\n\", freq, \"\\n\")\n","\n","print(\"The % percentage of attributes of each class: \\n\", percentage,)"]},{"cell_type":"markdown","metadata":{"id":"VAtitEtXiqQp"},"source":["# Επισκόπηση Data Set.\n","## **Κ11: Online Poker Games, One Dollar Spin \u0026 Go**\n","\n","To dataset περιέχει δεδομένα που έχουν συλλεχθεί από διαδικτυακές παρτίδες πόκερ, κυρίως τουρνουά τύπου \"Spin \u0026 Go\". Συγκεκριμένα κάθε εγγραφή του dataset περιγράφει το *πώς* έπαιξε ένας παίκτης σε κάποια παρτίδα και το τελικό αποτέλεσμα, δηλ αν κέρδισε ή αν έχασε.\n","\n","* **Πλήθος δειγμάτων**: 102615 (γραμμές από το 0 εώς το 102614 στο .csv αρχέιο, η τελευταία κενή εντελώς)\n","* **Πλήθος χαρακτηριστικών**: 35\n","\n","Κάθε δείγμα του dataset περιέχει 35 χαρακτηριστικά ένα εκ των οποίων είναι το αποτέλεσμα και ένα το τελικό ποσό που κέρδισε ή έχασε ο παίκτης. Ορισμένα από τα υπόλοιπα χαρακτηριστικά αφορούν τη συγκεκριμένη παρτίδα και είναι κοινά για εγγραφές για διαφορετικούς παίκτες στην ίδια παρτίδα. Τέτοια χαρακτηριστικά είναι το id της παρτίδας, ο χρόνος διεξαγωγής της, τα χαρτιά που κατέβηκαν στο board, το μέγεθος του τραπεζιού, ο αριθμός παικτών κοκ. Υπάρχουν επίσης χαρακτηριστικά που περιγράφουν *πώς* έπαιξε ο συγκεκριμένος παίκτης στη συγκεκριμένη παρτίδα, όπως: η θέση του στο τραπέζι, τα χαρτιά του, οι ενέργειες και τα πονταρίσματά του σε κάθε γύρο πονταρίσματος, κα.\n","\n","* **Μη διατεταγμένα χαρακτηριστικά**: Όχι\n","* **Είδος όλων των χαρακτηριστικών**: \n","\n","**Με βάση τον δημιουργό του dataset**: Από τις 35 στήλες, οι 17 έχουν χαρακτηριστικά τύπου Integer, οι 13 τύπου String, οι 2 DateTime και 3 αναγράφονται ως \"Άλλο\".\n","\n","**Με βάση το dataset.info():** 19 στήλες με δεδομένα τύπου Integer, 15 με τύπου Object και 1 με τύπου Boolean.\n","\n","* **Απουσιάζουσες τιμές:** Οι μόνες απουσιάζουσες τιμές βρίσκονται στο χαρακτηριστικό combination (που είναι ο συνδυασμός των χαρτιών του παίκτη). Παρόλα αυτά η παράληψή τους δεν αποτελεί αμέλεια στη δημιουργία του dataset, αλλά σημαντικό στοιχείο για τον τρόπο παιχνιδιού του παίκτη. Σημαίνει ότι ο παίκτης δεν παρέμεινε μέχρι το τέλος της παρτίδας (είτε επειδή αποσύρθηκε, είτε επειδή αποσύρθηκαν όλοι οι άλλοι και η παρτίδα δεν ολοκληρώθηκε). Για αυτό το λόγο οι απουσιάζουσες τιμές γεμίζονται με τιμή \"no info\" ώστε να χρησιμοποιηθούν ως πληροφορία κατά την εκπαιδευση του νευρωνικού δικτύου.\n","\n","* Υπάρχουν επικεφαλίδες αλλά όχι αρίθμηση γραμμών.\n","\n","Οι ετικέτες των κλάσεων βρίσκονται στην προτελευταία στήλη, την **result** και είναι οι εξης:\n","\n","* 1) gave up: Ο παίκτης αποσύρθηκε από την παρτίδα.\n","\n","* 2) lost: Ο παίκτης έμεινε στη διεκδίκηση του γύρου μέχρι το τέλος, έδειξε τα χαρτιά του αλλά έχασε γιατί κάποιος άλλος παίκτης είχε πιο ισχυρό συνδυασμό χαρτιών.\n","\n","* 3) won: Ο παίκτης έμεινε στη διεκδίκηση του γύρου μέχρι το τέλος, έδειξε τα χαρτιά του αλλά κέρδισε γιατί είχε τον πιο ισχυρό συνδυασμό χαρτιών.\n","\n","* 4) took chips: Ο παίκτης ήταν ο μόνος που παρέμεινε στην παρτίδα αφού όλοι οι άλλοι αποσύρθηκαν.\n","\n","\n","* **Ισορροπία Dataset:** Παρατηρούμε πως το dataset δεν είναι απόλυτα ισορροπημένο καθώς στο ποσοστό των δειγμάτων ανά κλάση υπάρχει μεγάλη απόκλιση, καθώς οι κλάσεις gave up και took chips είναι πάνω απο 1.5 φορές (2/3) πιο συχνές από τις won και lost.\n","\n","\n","## Notes για το dataset\n","\n","*   Αφαιρούμε το balance καθώς είναι αποτέλεσμα των υπόλοιπων στηλών και αν το αφήσουμε στο dataset θα βγάλουμε πολύ υψηλά scores στο training. Κρατάμε μόνο τις κλάσεις του results \n","\n","\n","## Μετρική\n","\n","Επιλέγουμ την f1 ως μετρική, καθώς συνδυάζει τα αποτελέσματα των μετρικών recall και precision και δίνει μια πιο γενική άποψη για την επίδοση του ταξινομητή, παρόλο που το αποτέλεσμα της δεν ερμηνεύεται πρακτικά τόσο εύκολα όσο η accuracy. Το πρόβλημα το οποίο πραγματεύεται το dataset δεν έχει να κάνει με κάποιο πρόβλημα υγείας ή κάτι αντίστοιχο επομένως δεν χρειάζεται να αξιολογηθεί η επίδοση του ταξινομητή δίνοντας προτεραιότητα σε κάποιο συγκεκριμένο κριτήριο όπως κάνουν οι recall και precision. Επίσης, η f1 διαχειρίζεται καλύτερα imbalanced (μη-ισορροπημένα) dataset όπως αυτό που χρησιμοποιούν οι out-of-the box ταξινομητές άρα ή σύγκριση με τους βελτιστοποιημένους (που χρησιμοποιούν ισορροπημένα datasets) είναι πιο αντικειμενική."]},{"cell_type":"markdown","metadata":{"id":"oO-s7Zi3wDez"},"source":["### Όπως είπαμε πανω, οι απουσιάζουσες τιμές γεμίζονται με τιμή \"no info\" ώστε να χρησιμοποιηθούν ως πληροφορία κατά την εκπαιδευση του νευρωνικού δικτύου"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670348818216,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"taBk9P75wEFF"},"outputs":[],"source":["dataset[\"combination\"] = dataset['combination'].replace(np.nan, \"no info\")"]},{"cell_type":"markdown","metadata":{"id":"LeT-tN9imkE-"},"source":["## Προεπεξεργασία:\n","\n","Αρχικά αφαιρούμε στήλες των οποίων οι τιμές είναι σταθερές και δεν είναι χρήσιμες για την εκπαίδευση του μοντέλου. Αναλυτικά, αφαιρούνται:\n","* οι στήλες με χαρακτηριστικά για τα οποία ένας αντίπαλος παίκτης δεν μπορεί να έχει πληροφορία (πχ τα χαρτιά του αντιπάλου).\n","* οι στήλες με χαρακτηριστικά που έχουν ίδια τιμή για κάθε εγγραφή του dataset (πχ buyin, table, table_size, ante -- εξάλλου δεν προσφέρουν πληροφορία).\n","* οι στήλες με χαρακτηριστικά που δεν προσφέρουν ουσιαστική πληροφορία (πχ date, tourn_id, hand_id).\n","\n","Παράλληλα κρατήσαμε μόνο τα πρώτα 50000 δείγματα για λόγους απόδοσης (αφού βλέπουμε ότι οι μετρικές μένουν περίπου ίδιες). Τέλος χρησιμοποιήσαμε τη LabelEncoder() ώστε να μετατρέψουμε τις κλάσεις από Strings σε μη κατηγορικά δεδομένα."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":719,"status":"ok","timestamp":1670348818929,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"pYhAXEaHmkiu","outputId":"285c0e9f-88c0-4403-d74f-274667a05136"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['level', 'playing', 'stack', 'action_pre', 'action_flop', 'action_turn',\n","       'action_river', 'all_in', 'combination', 'pot_pre', 'pot_flop',\n","       'pot_turn', 'pot_river', 'blinds', 'bet_pre', 'bet_flop', 'bet_turn',\n","       'bet_river', 'result'],\n","      dtype='object')\n"]}],"source":["# preprocessing to make the data learnable\n","from sklearn import preprocessing\n","\n","# διατηρούμε τα πρώτα 50000 δείγματα για λόγους απόδοσης και καθώς συγκλίνει αρκετά κοντά με την απόσοδη όλων των δειγμάτων\n","dataset = dataset[0:50000]\n","\n","# μπορει να αντικατασταθει με την μέθοδο που λέει στις διαλέξεις\n","le = preprocessing.LabelEncoder()\n","dataset['result'] = le.fit_transform(dataset['result'])\n","\n","# remove unessecary columns\n","dataset = dataset.drop(['buyin', 'date', 'time', 'name', 'seat', 'tourn_id', 'hand_id', 'balance', 'position', 'cards', 'board_flop', 'board_turn', 'board_river', 'table', 'table_size', 'ante'],axis=1)\n","# change non categorical to categorical\n","print(dataset.columns)\n","dataset = pd.get_dummies(dataset, columns=[list(dataset.columns)[i] for i in range(3, 9)])"]},{"cell_type":"markdown","metadata":{"id":"5v3aeiR-kJYd"},"source":["# Επίδοση out-of-the-box"]},{"cell_type":"markdown","metadata":{"id":"Q1h00eKQK6Qu"},"source":["Δαχωρίζουμε το σύνολο δεδομένων σε σύνολο εκπαίδευσης (train set) και σύνολο δοκιμών (test set) με 30% των δειγμάτων στο test set:"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670348818929,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"JbEb3CLtkU49"},"outputs":[],"source":["# split train and test sets\n","features = dataset.drop('result', axis=1)\n","labels = dataset['result']\n","\n","train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.30)"]},{"cell_type":"markdown","metadata":{"id":"zqJ_RyqCK7Re"},"source":["# Dummy Classifiers with different Strategies:"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1670348819354,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"K2reSi9KP3Yp","outputId":"00bc87bd-52a1-48f4-c5f0-bf0b8043e9af"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.26      0.34     15317\n","           1       0.10      0.26      0.14      2964\n","           2       0.30      0.24      0.27      9272\n","           3       0.11      0.27      0.16      3232\n","\n","    accuracy                           0.25     30785\n","   macro avg       0.25      0.26      0.23     30785\n","weighted avg       0.36      0.25      0.28     30785\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.66     15317\n","           1       0.00      0.00      0.00      2964\n","           2       0.00      0.00      0.00      9272\n","           3       0.00      0.00      0.00      3232\n","\n","    accuracy                           0.50     30785\n","   macro avg       0.12      0.25      0.17     30785\n","weighted avg       0.25      0.50      0.33     30785\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.49      0.49     15317\n","           1       0.10      0.10      0.10      2964\n","           2       0.30      0.31      0.31      9272\n","           3       0.10      0.10      0.10      3232\n","\n","    accuracy                           0.36     30785\n","   macro avg       0.25      0.25      0.25     30785\n","weighted avg       0.36      0.36      0.36     30785\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.66     15317\n","           1       0.00      0.00      0.00      2964\n","           2       0.00      0.00      0.00      9272\n","           3       0.00      0.00      0.00      3232\n","\n","    accuracy                           0.50     30785\n","   macro avg       0.12      0.25      0.17     30785\n","weighted avg       0.25      0.50      0.33     30785\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00     15317\n","           1       0.10      1.00      0.18      2964\n","           2       0.00      0.00      0.00      9272\n","           3       0.00      0.00      0.00      3232\n","\n","    accuracy                           0.10     30785\n","   macro avg       0.02      0.25      0.04     30785\n","weighted avg       0.01      0.10      0.02     30785\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["import random\n","outofthebox_dictionary_f1 = {}\n","strategies = ['uniform', 'most_frequent', 'stratified', 'prior', 'constant']\n","dummy_names = ['unifrom','most_frequent','stratified', 'prior', 'constant']\n","name=0\n","for strategy in strategies:\n","  if(strategy == 'constant'):\n","   no = random.choice([0,1,2,3])\n","   dummy = DummyClassifier(strategy = strategy, constant = no)\n","   dummy = dummy.fit(train, train_labels)\n","   dummyname = 'constant' + str(no)\n","  else: \n","    dummy = DummyClassifier(strategy = strategy)\n","    dummy = dummy.fit(train, train_labels)\n","    dummyname = dummy_names[name]\n","  dummy_pred = dummy.predict(test)\n","  outofthebox_dictionary_f1[dummyname] = f1_score(test_labels, dummy_pred, average=\"macro\")\n","  print(classification_report(test_labels, dummy_pred))\n","  name = name + 1"]},{"cell_type":"markdown","metadata":{"id":"Tfl5faLzjNX-"},"source":["# **MLP**"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267747,"status":"ok","timestamp":1670349087098,"user":{"displayName":"Ορέστης Ζάρας","userId":"11939396594041811352"},"user_tz":-120},"id":"XMjhFnCXjxC5","outputId":"394be81c-afa0-4e8a-90a7-c2a28cf3cdfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     15317\n","           1       0.66      0.82      0.73      2964\n","           2       1.00      1.00      1.00      9272\n","           3       0.79      0.62      0.69      3232\n","\n","    accuracy                           0.94     30785\n","   macro avg       0.86      0.86      0.86     30785\n","weighted avg       0.95      0.94      0.94     30785\n","\n"]}],"source":["# for the MLP default \n","clf = MLPClassifier()\n","clf.fit(train, train_labels)\n","MLP_preds = clf.predict(test)\n","outofthebox_dictionary_f1['MLP'] = f1_score(test_labels, MLP_preds, average=\"macro\")\n","\n","print(classification_report(test_labels, MLP_preds))"]},{"cell_type":"markdown","metadata":{"id":"luvb8bDfjjbK"},"source":["# **SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b4fn0W7lQqQX"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      1.00      0.95     15317\n","           1       0.56      0.09      0.16      2964\n","           2       0.93      0.97      0.95      9272\n","           3       0.52      0.63      0.57      3232\n","\n","    accuracy                           0.86     30785\n","   macro avg       0.73      0.67      0.66     30785\n","weighted avg       0.84      0.86      0.83     30785\n","\n"]}],"source":["# for the SVC default\n","svm = SVC()\n","svm.fit(train, train_labels)\n","\n","SVM_preds = svm.predict(test)\n","outofthebox_dictionary_f1['SVM'] = f1_score(test_labels, SVM_preds, average=\"macro\")\n","\n","\n","print(classification_report(test_labels, SVM_preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8dcO_JDdQodp"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 720x720 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["from matplotlib import _png \n","fig, (ax) = plt.subplots( figsize=(10, 10))\n","\n","ax.set_title('f1 score')\n","ax.bar(outofthebox_dictionary_f1.keys(), outofthebox_dictionary_f1.values(), width=0.4)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"r79HDZWLM6xM"},"source":["**Παρατηρήσεις:**\n","\n","Παρατηρούμε ότι οι επιδόσεις out of the box ταξινόμησης είναι πολύ χαμηλές εκτός του MLP και του SVM, που λαμβάνουν αρκετά υψηλές τιμές.\n"," \n","Για τους υπόλοιπους ταξινομητές παρατηρείται ότι οι επιδόσεις τους είναι αναμενόμενα χαμηλές και εξαρτώνται από την κατανομή των δεδομένων σε κλάσεις.\n","Για να ανεβάσουμε την επίδοση θα εκτελέσουμε διάφορες τεχνικες:\n"]},{"cell_type":"markdown","metadata":{"id":"ciSUb8-JZwZm"},"source":["# GridSearch, pipeline and improvement to SVM and MLP parameters using **Optuna**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pLLYhGVl_eNJ"},"outputs":[],"source":["import sklearn\n","import optuna\n","\n","from sklearn.metrics import f1_score, accuracy_score\n","from imblearn.pipeline import Pipeline\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC \n","from sklearn.model_selection import GridSearchCV\n"]},{"cell_type":"markdown","metadata":{"id":"oDZ_oUbq4enP"},"source":["## **MLP Optimization**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1130,"status":"ok","timestamp":1670335079546,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"FyI0naey7f-P","outputId":"21b6f986-450f-455e-85d7-60614a560bce"},"outputs":[{"name":"stdout","output_type":"stream","text":["level                                           1.630970\n","playing                                         0.242580\n","stack                                       64751.426547\n","pot_pre                                     90384.699031\n","pot_flop                                   108940.384405\n","                                               ...      \n","combination_two pair, Tens and Nines            0.000654\n","combination_two pair, Tens and Sevens           0.000626\n","combination_two pair, Tens and Sixes            0.000598\n","combination_two pair, Tens and Threes           0.000376\n","combination_two pair, Threes and Deuces         0.000390\n","Length: 468, dtype: float64\n","124334.27302584756\n","469\n"]}],"source":["scaler_t = MinMaxScaler()\n","train_t = train\n","train_t = scaler_t.fit_transform(train_t)\n","\n","print(train_t.var(axis=0))\n","print(max(train_t.var(axis=0)))\n","print(len(dataset.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3235207,"status":"ok","timestamp":1670338580163,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"tk5W3JRGaDRk","outputId":"61be287e-1864-40be-abb8-3b988a317b34"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","120 fits failed out of a total of 150.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","30 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 262, in fit\n","    Xt, yt = self._fit(X, y, **fit_params_steps)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 210, in _fit\n","    X, fitted_transformer = fit_transform_one_cached(\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 594, in __call__\n","    return self._cached_call(args, kwargs)[0]\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 537, in _cached_call\n","    out, metadata = self.call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 779, in call\n","    output = self.func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n","    res = transformer.fit_transform(X, y, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 855, in fit_transform\n","    return self.fit(X, y, **fit_params).transform(X)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_variance_threshold.py\", line 120, in fit\n","    raise ValueError(msg.format(self.threshold))\n","ValueError: No feature in X meets the variance threshold 2500.00000\n","\n","--------------------------------------------------------------------------------\n","30 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 262, in fit\n","    Xt, yt = self._fit(X, y, **fit_params_steps)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 210, in _fit\n","    X, fitted_transformer = fit_transform_one_cached(\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 594, in __call__\n","    return self._cached_call(args, kwargs)[0]\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 537, in _cached_call\n","    out, metadata = self.call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 779, in call\n","    output = self.func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n","    res = transformer.fit_transform(X, y, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 855, in fit_transform\n","    return self.fit(X, y, **fit_params).transform(X)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_variance_threshold.py\", line 120, in fit\n","    raise ValueError(msg.format(self.threshold))\n","ValueError: No feature in X meets the variance threshold 5000.00000\n","\n","--------------------------------------------------------------------------------\n","30 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 262, in fit\n","    Xt, yt = self._fit(X, y, **fit_params_steps)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 210, in _fit\n","    X, fitted_transformer = fit_transform_one_cached(\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 594, in __call__\n","    return self._cached_call(args, kwargs)[0]\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 537, in _cached_call\n","    out, metadata = self.call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 779, in call\n","    output = self.func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n","    res = transformer.fit_transform(X, y, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 855, in fit_transform\n","    return self.fit(X, y, **fit_params).transform(X)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_variance_threshold.py\", line 120, in fit\n","    raise ValueError(msg.format(self.threshold))\n","ValueError: No feature in X meets the variance threshold 7000.00000\n","\n","--------------------------------------------------------------------------------\n","30 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 262, in fit\n","    Xt, yt = self._fit(X, y, **fit_params_steps)\n","  File \"/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py\", line 210, in _fit\n","    X, fitted_transformer = fit_transform_one_cached(\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 594, in __call__\n","    return self._cached_call(args, kwargs)[0]\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 537, in _cached_call\n","    out, metadata = self.call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 779, in call\n","    output = self.func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n","    res = transformer.fit_transform(X, y, **fit_params)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 855, in fit_transform\n","    return self.fit(X, y, **fit_params).transform(X)\n","  File \"/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_variance_threshold.py\", line 120, in fit\n","    raise ValueError(msg.format(self.threshold))\n","ValueError: No feature in X meets the variance threshold 10000.00000\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77726438        nan        nan        nan        nan 0.80150697\n","        nan        nan        nan        nan 0.83896079        nan\n","        nan        nan        nan 0.84136835        nan        nan\n","        nan        nan 0.84133238        nan        nan        nan\n","        nan 0.84257815        nan        nan        nan        nan]\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/imblearn/pipeline.py:210: UserWarning: Persisting input arguments took 0.84s to run.\n","If this happens often in your code, it can cause performance problems \n","(results will be correct in all cases). \n","The reason for this is probably some large input arguments for a wrapped\n"," function (e.g. large strings).\n","THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n"," example so that they can fix the problem.\n","  X, fitted_transformer = fit_transform_one_cached(\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     15177\n","           1       0.70      0.69      0.69      3055\n","           2       1.00      1.00      1.00      9350\n","           3       0.71      0.72      0.71      3203\n","\n","    accuracy                           0.94     30785\n","   macro avg       0.85      0.85      0.85     30785\n","weighted avg       0.94      0.94      0.94     30785\n","\n","Pipeline(memory='tmp',\n","         steps=[('scaler', MinMaxScaler()),\n","                ('selector', VarianceThreshold(threshold=0)),\n","                ('sampler', RandomOverSampler()),\n","                ('pca', PCA(n_components=100)), ('MLP', MLPClassifier())])\n"]}],"source":["mlp = MLPClassifier()\n","\n","scaler = MinMaxScaler() \n","selector = VarianceThreshold() # 0 το καλύτερο λογω χαμηλού μέσης τιμής variance των χαρακτηρηστικων \n","ros = RandomOverSampler()\n","pca = PCA()\n","\n","n_components = [5, 10, 20, 30, 50, 100] # CURRENT BEST: 30\n","vthreshold = [0, 2500, 5000, 7000, 10000] # CURRENT BEST: 0\n","\n","# # create the pipeline\n","pipe_MLP = Pipeline(steps=[('scaler', scaler), ('selector', selector), ('sampler', ros), ('pca', pca), ('MLP', mlp)], memory='tmp')\n","estimator_MLP = GridSearchCV(pipe_MLP, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)\n","\n","estimator_MLP.fit(train, train_labels)\n","preds_pipeline_MLP = estimator_MLP.predict(test)\n","\n","\n","print(classification_report(test_labels, preds_pipeline_MLP))\n","print(estimator_MLP.best_estimator_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4080974,"status":"ok","timestamp":1670342661934,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"5N6ATn7kPB1D","outputId":"1dbbeb75-2dd8-49e2-d55e-7be848786d16"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-12-06 14:56:20,857]\u001b[0m A new study created in memory with name: no-name-ce120401-c561-4d21-b359-3409951eb034\u001b[0m\n","\u001b[32m[I 2022-12-06 14:57:16,238]\u001b[0m Trial 1 finished with value: 0.8710067884104644 and parameters: {'n_layers': 2, 'n_units_0': 12, 'n_units_1': 18, 'solver': 2, 'activation': 0, 'learning_rate': 1, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","\u001b[32m[I 2022-12-06 14:57:54,037]\u001b[0m Trial 2 finished with value: 0.8677965546816011 and parameters: {'n_layers': 2, 'n_units_0': 11, 'n_units_1': 12, 'solver': 2, 'activation': 0, 'learning_rate': 0, 'max_iter': 100, 'tol': 0.001, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","\u001b[32m[I 2022-12-06 14:59:39,934]\u001b[0m Trial 0 finished with value: 0.8659219637353054 and parameters: {'n_layers': 1, 'n_units_0': 16, 'solver': 2, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:00:12,511]\u001b[0m Trial 4 finished with value: 0.08068401266015976 and parameters: {'n_layers': 2, 'n_units_0': 10, 'n_units_1': 19, 'solver': 1, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 5}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:01:16,114]\u001b[0m Trial 5 finished with value: 0.8694661653377816 and parameters: {'n_layers': 1, 'n_units_0': 17, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:01:42,686]\u001b[0m Trial 6 finished with value: 0.6279443097527788 and parameters: {'n_layers': 1, 'n_units_0': 10, 'solver': 1, 'activation': 3, 'learning_rate': 1, 'max_iter': 300, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 1 with value: 0.8710067884104644.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:04:52,248]\u001b[0m Trial 7 finished with value: 0.8725585974363962 and parameters: {'n_layers': 2, 'n_units_0': 15, 'n_units_1': 13, 'solver': 0, 'activation': 1, 'learning_rate': 0, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:05:54,340]\u001b[0m Trial 8 finished with value: 0.867074717277619 and parameters: {'n_layers': 2, 'n_units_0': 19, 'n_units_1': 13, 'solver': 1, 'activation': 0, 'learning_rate': 0, 'max_iter': 100, 'tol': 0.001, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:06:26,190]\u001b[0m Trial 9 finished with value: 0.5877920864118721 and parameters: {'n_layers': 1, 'n_units_0': 19, 'solver': 1, 'activation': 3, 'learning_rate': 1, 'max_iter': 300, 'tol': 0.001, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:06:56,048]\u001b[0m Trial 10 finished with value: 0.6834322446328112 and parameters: {'n_layers': 1, 'n_units_0': 20, 'solver': 1, 'activation': 3, 'learning_rate': 1, 'max_iter': 100, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","\u001b[32m[I 2022-12-06 15:09:35,711]\u001b[0m Trial 3 finished with value: 0.8593608723178876 and parameters: {'n_layers': 1, 'n_units_0': 16, 'solver': 2, 'activation': 2, 'learning_rate': 0, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:10:35,721]\u001b[0m Trial 11 finished with value: 0.8691401781561484 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 10, 'solver': 0, 'activation': 2, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:12:19,820]\u001b[0m Trial 12 finished with value: 0.8693570549686921 and parameters: {'n_layers': 2, 'n_units_0': 13, 'n_units_1': 17, 'solver': 0, 'activation': 0, 'learning_rate': 2, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:13:20,933]\u001b[0m Trial 13 finished with value: 0.8679569149349575 and parameters: {'n_layers': 2, 'n_units_0': 13, 'n_units_1': 18, 'solver': 0, 'activation': 0, 'learning_rate': 2, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:14:49,566]\u001b[0m Trial 14 finished with value: 0.8684281085139905 and parameters: {'n_layers': 2, 'n_units_0': 12, 'n_units_1': 16, 'solver': 0, 'activation': 0, 'learning_rate': 0, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","\u001b[32m[I 2022-12-06 15:17:53,703]\u001b[0m Trial 15 finished with value: 0.8657974753637958 and parameters: {'n_layers': 2, 'n_units_0': 12, 'n_units_1': 15, 'solver': 2, 'activation': 1, 'learning_rate': 0, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","\u001b[32m[I 2022-12-06 15:23:30,205]\u001b[0m Trial 16 finished with value: 0.8656853690346274 and parameters: {'n_layers': 2, 'n_units_0': 15, 'n_units_1': 20, 'solver': 2, 'activation': 1, 'learning_rate': 0, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:24:24,847]\u001b[0m Trial 17 finished with value: 0.8578139687933934 and parameters: {'n_layers': 2, 'n_units_0': 15, 'n_units_1': 20, 'solver': 2, 'activation': 2, 'learning_rate': 0, 'max_iter': 200, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:27:56,035]\u001b[0m Trial 19 finished with value: 0.866595645341253 and parameters: {'n_layers': 2, 'n_units_0': 17, 'n_units_1': 14, 'solver': 1, 'activation': 0, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:28:39,951]\u001b[0m Trial 20 finished with value: 0.08169424767002138 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 11, 'solver': 1, 'activation': 1, 'learning_rate': 1, 'max_iter': 300, 'tol': 0.001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:30:33,406]\u001b[0m Trial 18 finished with value: 0.8699074853479436 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 14, 'solver': 1, 'activation': 2, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:32:32,884]\u001b[0m Trial 21 finished with value: 0.8668837885640589 and parameters: {'n_layers': 2, 'n_units_0': 12, 'n_units_1': 15, 'solver': 0, 'activation': 2, 'learning_rate': 1, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:34:30,831]\u001b[0m Trial 22 finished with value: 0.8690255583950571 and parameters: {'n_layers': 2, 'n_units_0': 13, 'n_units_1': 14, 'solver': 0, 'activation': 2, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:37:55,018]\u001b[0m Trial 23 finished with value: 0.8693560776796679 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 13, 'solver': 1, 'activation': 2, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:41:24,513]\u001b[0m Trial 25 finished with value: 0.8673752650236932 and parameters: {'n_layers': 2, 'n_units_0': 16, 'n_units_1': 17, 'solver': 2, 'activation': 1, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:42:36,936]\u001b[0m Trial 26 finished with value: 0.7296496225466886 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 12, 'solver': 1, 'activation': 2, 'learning_rate': 1, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:43:20,558]\u001b[0m Trial 27 finished with value: 0.17432635472047023 and parameters: {'n_layers': 2, 'n_units_0': 11, 'n_units_1': 15, 'solver': 1, 'activation': 1, 'learning_rate': 1, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:44:02,563]\u001b[0m Trial 28 finished with value: 0.868606296622805 and parameters: {'n_layers': 2, 'n_units_0': 15, 'n_units_1': 13, 'solver': 2, 'activation': 0, 'learning_rate': 0, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:44:20,453]\u001b[0m Trial 24 finished with value: 0.868756731687303 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 13, 'solver': 1, 'activation': 2, 'learning_rate': 2, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:45:08,183]\u001b[0m Trial 30 finished with value: 0.8671344221751525 and parameters: {'n_layers': 1, 'n_units_0': 17, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 200, 'tol': 0.001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:47:04,679]\u001b[0m Trial 31 finished with value: 0.86062767037168 and parameters: {'n_layers': 2, 'n_units_0': 11, 'n_units_1': 16, 'solver': 2, 'activation': 3, 'learning_rate': 0, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:48:14,724]\u001b[0m Trial 32 finished with value: 0.8669379688308342 and parameters: {'n_layers': 1, 'n_units_0': 17, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:49:23,596]\u001b[0m Trial 33 finished with value: 0.8664134358374739 and parameters: {'n_layers': 1, 'n_units_0': 18, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:50:28,994]\u001b[0m Trial 29 finished with value: 0.8661849321576871 and parameters: {'n_layers': 2, 'n_units_0': 17, 'n_units_1': 16, 'solver': 0, 'activation': 3, 'learning_rate': 2, 'max_iter': 300, 'tol': 0.001, 'early_stopping': False, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:50:29,772]\u001b[0m Trial 34 finished with value: 0.8671775580084247 and parameters: {'n_layers': 1, 'n_units_0': 16, 'solver': 0, 'activation': 0, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:51:45,937]\u001b[0m Trial 35 finished with value: 0.8689095655281688 and parameters: {'n_layers': 1, 'n_units_0': 16, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 15:51:48,068]\u001b[0m Trial 36 finished with value: 0.8714985725412202 and parameters: {'n_layers': 1, 'n_units_0': 16, 'solver': 0, 'activation': 1, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:52:50,883]\u001b[0m Trial 38 finished with value: 0.8723756763011037 and parameters: {'n_layers': 1, 'n_units_0': 13, 'solver': 2, 'activation': 2, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:53:21,550]\u001b[0m Trial 39 finished with value: 0.8675117760438692 and parameters: {'n_layers': 1, 'n_units_0': 10, 'solver': 2, 'activation': 0, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:54:00,445]\u001b[0m Trial 37 finished with value: 0.86498737518438 and parameters: {'n_layers': 1, 'n_units_0': 18, 'solver': 2, 'activation': 2, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:55:16,062]\u001b[0m Trial 40 finished with value: 0.8680718333384952 and parameters: {'n_layers': 1, 'n_units_0': 13, 'solver': 2, 'activation': 1, 'learning_rate': 0, 'max_iter': 100, 'tol': 0.0001, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","\u001b[32m[I 2022-12-06 15:56:09,660]\u001b[0m Trial 41 finished with value: 0.8686235159298925 and parameters: {'n_layers': 1, 'n_units_0': 13, 'solver': 2, 'activation': 1, 'learning_rate': 0, 'max_iter': 100, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:57:06,699]\u001b[0m Trial 42 finished with value: 0.8667102021955031 and parameters: {'n_layers': 1, 'n_units_0': 15, 'solver': 2, 'activation': 2, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:57:39,797]\u001b[0m Trial 44 finished with value: 0.7076679885252963 and parameters: {'n_layers': 1, 'n_units_0': 12, 'solver': 1, 'activation': 2, 'learning_rate': 1, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 15:57:55,385]\u001b[0m Trial 43 finished with value: 0.8648017780877485 and parameters: {'n_layers': 1, 'n_units_0': 15, 'solver': 1, 'activation': 2, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 5}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 16:00:00,602]\u001b[0m Trial 45 finished with value: 0.8677149786385752 and parameters: {'n_layers': 1, 'n_units_0': 15, 'solver': 1, 'activation': 2, 'learning_rate': 0, 'max_iter': 100, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 16:01:18,644]\u001b[0m Trial 47 finished with value: 0.8650004859629822 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 18, 'solver': 2, 'activation': 3, 'learning_rate': 1, 'max_iter': 300, 'tol': 0.001, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","\u001b[32m[I 2022-12-06 16:02:33,287]\u001b[0m Trial 46 finished with value: 0.861328175896676 and parameters: {'n_layers': 2, 'n_units_0': 14, 'n_units_1': 18, 'solver': 2, 'activation': 3, 'learning_rate': 1, 'max_iter': 300, 'tol': 1e-05, 'early_stopping': True, 'n_iter_no_change': 10}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 16:03:50,373]\u001b[0m Trial 48 finished with value: 0.867281921393481 and parameters: {'n_layers': 2, 'n_units_0': 11, 'n_units_1': 14, 'solver': 0, 'activation': 0, 'learning_rate': 1, 'max_iter': 200, 'tol': 1e-05, 'early_stopping': False, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","\u001b[32m[I 2022-12-06 16:04:21,826]\u001b[0m Trial 49 finished with value: 0.8692781366295896 and parameters: {'n_layers': 2, 'n_units_0': 11, 'n_units_1': 14, 'solver': 0, 'activation': 0, 'learning_rate': 1, 'max_iter': 200, 'tol': 0.0001, 'early_stopping': False, 'n_iter_no_change': 15}. Best is trial 7 with value: 0.8725585974363962.\u001b[0m\n"]}],"source":["# create objective\n","def objective_MLP(trial):\n","  n_layers = trial.suggest_int('n_layers', 1, 2)\n","  layers = []\n","  for i in range(n_layers):\n","      layers.append(trial.suggest_int(f'n_units_{i}', 10, 20))\n","\n","\n","  solvers=['lbfgs', 'sgd', 'adam']\n","  solver_index = trial.suggest_int(\"solver\", 0, 2)\n","\n","  activations = ['identity', 'logistic', 'tanh', 'relu']\n","  activation_index = trial.suggest_int('activation', 0, 3)\n","\n","  learning_rates = [\"constant\", \"invscaling\", \"adaptive\"]\n","  learning_rates_index = trial.suggest_int(\"learning_rate\", 0, 2)\n","\n","  max_iter = trial.suggest_categorical(\"max_iter\", [100, 200, 300])\n","  tol = trial.suggest_categorical(\"tol\", [1e-3, 1e-4, 1e-5])\n","  early_stopping = trial.suggest_categorical(\"early_stopping\", [False, True])\n","  n_iter_no_change = trial.suggest_categorical(\"n_iter_no_change\", [5, 10, 15])\n","\n","  global train, test, train_labels, test_labels\n","  mlp = MLPClassifier(activation=activations[activation_index],solver=solvers[solver_index] ,hidden_layer_sizes=tuple(layers), learning_rate = learning_rates[learning_rates_index], \n","    max_iter = max_iter, tol = tol, early_stopping = early_stopping, n_iter_no_change = n_iter_no_change)\n","\n","  selector = VarianceThreshold(threshold=0)\n","  scaler = MinMaxScaler()\n","  ros = RandomOverSampler()\n","  pca = PCA(n_components=100)\n","  pipeline = Pipeline(steps = [('scaler', scaler), ('selector', selector),  ('sampler', ros), ('pca', pca), ('MLP', mlp)])\n","  pipeline.fit(train, train_labels)\n","  preds = pipeline.predict(test)\n","\n","  return f1_score(preds, test_labels, average='macro')\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective_MLP, n_trials=30, n_jobs=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0e1G5xjk3tM"},"outputs":[],"source":["# best mlp pipe with fit\n"]},{"cell_type":"markdown","metadata":{"id":"2FM5D-oVm1HP"},"source":["## **SVC optimization**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"error","timestamp":1670342661934,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"4ILZvMHrtpO-","outputId":"5782c6ae-3e12-4c04-e65e-ba4d7ccc2d6a"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-22-60297e65830b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# create the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 14\u001b[0;31m \u001b[0mpipe_SVC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'selector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;34m'sampler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'SVC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mestimator_SVC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe_SVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector__threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca__n_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'svc' is not defined"]}],"source":["#  based on best parameters\n","svc = SVC()\n","\n","scaler = MinMaxScaler()\n","selector = VarianceThreshold()\n","ros = RandomOverSampler()\n","pca = PCA()\n","\n","vthreshold = [0, 0.01, 0.02, 0.03]\n","n_components = [5, 10, 20, 30, 50, 100]\n","\n","\n","# create the pipeline\n","pipe_SVC = Pipeline(steps=[('scaler', scaler), ('selector', selector),  ('sampler', ros), ('pca', pca), ('SVC', svc)], memory='tmp')\n","estimator_SVC = GridSearchCV(pipe_SVC, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=5, scoring='f1_macro', n_jobs=-1)\n","\n","estimator_SVC.fit(train, train_labels)\n","preds_pipeline_SVC = estimator_SVC.predict(test)\n","\n","print(classification_report(test_labels, preds_pipeline_SVC))\n","print(estimator_SVC.best_estimator_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"br_zuaZXm6LG"},"outputs":[],"source":["# create objective\n","def objective_SVC(trial):\n","  m_C = trial.suggest_float(\"C\", 0, 1)\n","  m_degree = trial.suggest_int(\"degree\", 1, 10)\n","\n","  # cant be precomputed matrix \n","  kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n","  kernel_index = trial.suggest_int(\"kernel\", 0, 3)\n","  gamma = trial.suggest_loguniform(\"gamma\", 20.0, 100.0)\n","  tol = trial.suggest_categorical(\"tol\", [1e-3, 1e-4, 1e-5])\n","  max_iter = trial.suggest_categorical(\"max_iter\", [10000])\n","  \n","  \n","  global train, test, train_labels, test_labels\n","  \n","  svm = SVC(C=m_C, kernel=kernels[kernel_index] , degree=m_degree, gamma = gamma, tol = tol, max_iter = max_iter)\n","  # #ΔΙΚΕΣ ΜΟΥ ΑΛΛΑΓΕΣ, ΑΝ ΔΕΝ ΤΑΙΡΙΑΖΟΥΝ ΜΕ ΤΑ ΚΑΤΩ ΣΒΗΣΤΑ\n","  \n","  selector = VarianceThreshold(threshold=0)\n","  scaler = MinMaxScaler()\n","  ros = RandomOverSampler()\n","  pca = PCA(n_components=100)\n","  pipeline = Pipeline(steps = [('scaler', scaler), ('selector', selector),  ('sampler', ros), ('pca', pca), ('SVC', svm)])\n","  pipeline.fit(train, train_labels)\n","  preds = pipeline.predict(test)\n","\n","  return f1_score(preds, test_labels, average='macro')\n","  \n","  \n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective_SVC, n_trials=20, n_jobs=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug60aQ_Ak9TS"},"outputs":[],"source":["#best svc pipe"]},{"cell_type":"markdown","metadata":{"id":"Xt-P4UMjPDmU"},"source":["### **Παρατηρήσεις για τον MLP:**\n","\n","Στην περίπτωση του MLP έγιναν δοκιμές χρησιμοποιώντας ολόκληρο το dataset. Έγιναν δοκιμές για πολλές υπερπαραμέτρους με τη διαδικασία που αναφέρεται πιο κάτω και στο τέλος κρατήθηκαν οι εξής: hidden_layer_sizes, activation, solver, learning_rate, max_iter, tol, early_stopping, n_iter, no_change. ***(Αξίζει να σημειωθεί ότι έγιναν δοκιμές με πιο πιο περιορισμένα εύρη τιμών απο αυτά που φαίνονται πιο πάνω και η επίδοση δεν ξεπερνούσε το 0.87, πιο πάνω φαίνεται μια πιο γενική προσπάθεια που και πάλι δεν κατάφερε να ξεπεράσει το ταβάνι του 0.87.)***\n","\n","Για το pipeline επιλέχθηκε η σειρά έδινε καλύτερα αποτελέσματα: sampler \u003e selector \u003e scaler \u003e pca \u003e classifier.\n","\n","Ο sampler χρησιμοποιήθηκε διότι το αρχικό dataset δεν είναι ισορροπημένο\n","\n","Για τον selector παρατηρείται ότι δεν αφαίρεσε κανένα χαρακτηριστικό αφού στις περισσότερες καλές δοκιμές τα διατηρεί όλα επομένως ήταν όλα χρήσιμα\n","\n","***Για τον scaler χρησιμοποιήθηκαν MinMax (κανονικοποίηση δεδομένων στο [-1,1]) και standard (κανονικοποίηση δεδομένων στο [0,1]),*** γενικά κανένας από τους δύο δεν φάνηκε να υπερέχει σημαντικά ***αλλά ο βέλτιστος ταξινομητής χρησιμοποιεί τον StandardScaler.***\n","\n","O pca χρησιμοποιείται για να μειωθεί η διαστατικότητα του dataset η οποία είναι μεγάλη διότι κάποια χαρακτηριστικά έχουν μεγάλο εύρος τιμών (πχ ο τρόπος παιχνιδιού του παίκτη σε κάθε γύρο πονταρίσματος -- χαρακτηριστικά action).\n","\n","Για την υπερπαράμετρο n_components παρατηρήσαμε ότι η επίδοση βελτιώνεται για τιμή ίση με ***23 (ΓΙΑ ΕΜΑΣ 19 ΕΙΝΑΙ, ΤΣΕΚΑΡΕ ΑΝ ΙΣΧΥΕΙ) *** \n","\n","***Η Relu είχε σταθερά καλύτερη επίδοση από όλες τις activation functions του hidden layer***\n","\n","***Για το hidden_layer_size οι τιμές που δοκιμάσαμε δεν είχαν μεγάλη επίδραση στην επίδοση***"]},{"cell_type":"markdown","metadata":{"id":"i1tIkoHqvV6-"},"source":["### **Παρατηρήσεις για τον SVM:**\n","\n","*** Αρχικά έγινε δοκιμή για ολόκληρο το dataset όμως η διάρκεια εκτέλεσης ήταν απαγορευτική και οδηγούσε σε αποσύνδεση από το colab. Για αυτό το λόγο έγινε stratified sampling και διατηρήθηκε περιπου το 50% των δειγμάτων, δηλαδη 50000 δείγματα *** **(δοκιμάσαμε να το τρέξουμε με 10 χιλιάδες, 20, 30 κλπ χιλιάδες και είδαμε πως μέχρι τα 50,000 τρέχει κανονικά, μετά αργεί υπερβολικά πολύ και αποσυνδέεται το colab (crashάρει))**. Στη συνέχεια έγινε δοκιμή για πολλές υπερπαραμέτρους με τη διαδικασία που αναφέρεται πιο κάτω και στο τέλος κρατήθηκαν οι εξής: C, kernel, degree, gamma, tol, max_iter.\n","\n","***Συγκεκριμένα δοκιμάσαμε τους scalers MinMax και Standard και από τους δύο φαινόταν να έχει σταθερά καλύτερη απόδοση ο Standard***\n","\n","Επίσης, μετά απο πολλές δοκιμές στα n_components σε διάφορα εύρη τιμή μέχρι το ***19 (συνολικός αριθμός χαρακτηριστικών) παρατηρήθηκε ότι για λιγότερα από 19 οι τιμές ήταν χειρότερες επομένως διατηρήσαμε τη τιμή της υπερπαραμέτρου στο 19***\n","\n","Σχετικά με το kernel καλύτερη επίδοση κατά κανόνα παρουσιάζονταν ***για τιμή \"poly\"***\n","\n","Για το degree έγιναν δοκιμές στο εύρος 1-50 και παρατηρήθηκε ότι βέλτιστη επίδοση υπήρχε για τιμές κοντά στο ***5 γύρω από το οποίο έγιναν καινούργιες δοκιμές με πιο περιορισμένο εύρος και μικρότερο βήμα. Στη συνέχεια παρατηρήσαμε ότι η καλύτερη τιμή ήταν το 5 το οποίο τελικά και διατήρσαμε***\n","\n","Για την υπερπαράμετρο gamma ξεκινήσαμε από πολύ μεγάλο παράθυρο τιμών και καταλήξαμε ότι*** βέλτιστα αποτελέσματα παρουσιάζονταν για τιμές στο παράθυρο 20-100***\n","\n","Για την υπερπαράμετρο max_iter παρατηρήθηκε ότι τιμές που ξεπερνούσαν ***τις 2000 δεν υπήρχε αισθητή διαφορά. Τελικά όμως επιλέχθηκε η τιμή 3000 γιατί έδινε ελαφρώς καλύτερα αποτελέσματα***"]},{"cell_type":"markdown","metadata":{"id":"cEA1i9mAP9DH"},"source":["## Αποτελεσματα \u0026 Παρατηρήσεις:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VspBcpeQEOl"},"outputs":[],"source":["plt.figure(figsize = (12, 10))\n","labels = [\"MLP\", \"SVM\"]\n","indices = np.arange(len(labels))\n","plt.bar(indices, [clf, svm], width = 0.40, label = 'Out of the box')\n","plt.bar(indices + 0.40, [mlp_best, svc_best], width = 0.40, label = 'Optimized')\n","plt.xticks(ticks = indices, labels = labels)\n","plt.legend()\n","plt.xlabel(\"Classifier\")\n","plt.ylabel(\"F1 Score\")\n","plt.title(\"Out of the box VS Optimized on F1 and MLP vs SVM\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TE4GoXNLPpNK"},"source":["## **Τεκμηρίωση της Διαδικασίας:**\n","\n","*Η λογική ήταν να δοκιμάσουμε αρχικά αρκετές υπερπαραμέτρους και για κάθε μία να δοκιμάσουμε τη default τιμή, αρκετά μεγαλύτερες και αρκετά μικρότερες.*\n","\n","* Όταν παρατηρούσαμε ότι η υπερπαράμετρος δεν παρουσίαζε σημαντική επηρροή στα αποτελέσματα για πολύ διαφορετικές τιμές της, θεωρούσαμε ότι δεν χρειάζεται να εξετάζεται από το Optuna. Αντιθέτως, για υπερπαραμέτρους των οποίων η μεταβολή των τιμων επηρέαζε την επίδοση, επιλέγαμε ένα εύρος γύρω από την τιμή που έδινε καλύτερο αποτέλεσμα και επαναλαμβάναμε τη διαδικασία.\n","\n","* Επίσης υπήρχαν υπερπαραμέροι για τις οποίες ήταν ξεκάθαρο ποιά τιμή έδινε καλύτερο αποτέλεσμα. ***Για παράδειγμα για τον MLP η Relu ήταν με διαφορά η πιο αποδοτική activation function.***\n","\n","* Παράλληλα υπήρχαν τιμές υπερπαραμέτρων οι οποίες έδιναν σταθερά χειρότερα αποτελέσμτα. Για παράδειγμα για τον ***SVM η sigmoid ήταν με διαφορά η χειρότερη δυνατή επιλογή ως kernel type.***\n","\n","* Για τη μορφή του pipeline, χρησιμοποιήθηκαν τα ***4 στάδια του pipeline (sampler, scaler, pca, selector) σε διάφορες αλληλουχίες μέχρι να καταλήξουμε στην τελική μορφή.***\n","\n","* Ακόμη, φάνηκε ότι σε κάθε περίπτωση όλα τα 19 χαρακτηριστικά ήταν απαραίτητα αφού οποιαδήποτε παράληψη χαρακτηριστικού είχε αρνητική επίδραση στην απόδοση.\n","\n","### **Παρατηρήσεις:**\n","Για τον MLP ταξινομητή ακόμα και η out-of-the-box υλοποίηση έδινε ικανοποιητικά αποτελέσματα. Μετά από τις διάφορες δοκιμές που έγιναν για βελτιστοποίηση καταφέραμε να ξεπεράσουμε την τιμή ***0.865*** η οποία είναι ικανοποιητική. Αυτό συμβαίνει διότι από τα δεδομένα που υπάρχουν στο dataset για πολλές παρτίδες είναι δύσκολο ακόμα και για τον άνθρωπο να εκτιμήσει σωστά το αποτέλεσμα. ***Επίσης ο παράγοντας της μπλόφας σε παιχνίδια πόκερ είναι δύσκολο να συνυπολογιστεί από το νευρωνικό δίκτυο με μεγάλη ακρίβεια.***\n","\n","Για τον SVM η out-of-the-box υλοποίηση έδινε λιγότερο ικανοποιητικά, αλλά και πάλι αξιοπρεπή αποτελέσματα. Με διάφορες δοκιμές που έγιναν κατά τη βελτιστοποίηση καταφέραμε να αυξήσουμε σημαντικά την επίδοση. Παρόλα αυτά οι επιδόσεις του παρέμειναν σταθερά πιο κάτω από του MLP, ενώ ήταν πολύ πιο χρονοβόρα διαδικασία."]},{"cell_type":"markdown","metadata":{"id":"TCcOcsUsPsZR"},"source":["## **Συμπέρασμα:**\n","***Για το συγκεκριμένο dataset φαίνεται ότι προφανώς η βέλτιστη επιλογή είναι ο MLP ταξινομητής αφού δίνει σταθερά καλύτερα αποτελέσματα σύμφωνα με τη μετρική f1 που χρησιμοποιήθηκε.*** \n","\n","Επίσης υπερτερεί σημαντικά στο χρόνο εκπαίδευσης διότι μπορεί να διαχειριστεί ολόκληρο το dataset σε μικρό (σχετικά με τον SVM) χρόνο, ενώ ο SVM αδυνατούσε να το διαχειριστεί κα***ι χρειάστηκε να γίνει εκπαίδευση σε ένα ποσοστό των δειγμάτων του dataset.*** Από τις διάφορες δοκιμές που έγιναν δεν βρέθηκε κανένα κριτήριο σύμφωνα με το οποίο ο SVM να έχει καλύτερη επίδοση από τον MLP"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"2e3f13501ba77f252a9a3d481eee3ca7e4134263fbb542e82fd7fd34bc2945df"}}},"nbformat":4,"nbformat_minor":0}